{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38tA-ErIC4OD"
   },
   "source": [
    "# Proyecto: Análisis de mercado inmobiliario\n",
    "\n",
    "El principal objetivo de este proyecto es mejorar los resultados obtenidos en una primera instancia.\n",
    "1. Mejorar los resultados en lo que respecta a código, hacerlo mas eficiente e intentar optimizar memoria del equipo.\n",
    "1. Mejorar el analisis EDA para una mejor comprensión de nuestros datos.\n",
    "1. Mejorar los resultados obtenidos en la predicción del modelo.\n",
    "1. Incorporar un mapa iteractivo para poder visualizar el precio de las propiedades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos herramientas a utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dataset properati.](https://drive.google.com/uc?export=download&id=1Ugbsw5XbNRbglomSQO1qkAgMFB_3BzmB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "sns.set()\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "import xgboost as xgb\n",
    "from wordcloud import WordCloud, STOPWORDS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTAMOS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = pd.read_csv('DS_Proyecto_01_Datos_Properati.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CAMBIAMOS NOMBRE A LAS COLUMNAS'''\n",
    "propiedades = properties.rename(columns={'l1': 'country','l2':'zone','l3':'quarter'})\n",
    "propiedades.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMENZAMOS A REALIZAR EL PREPROCESAMIENTO DE DATOS.**\n",
    "\n",
    "1. Selecciona la zona y tipo de propiedades con mayor cantidad de propiedades.\n",
    "1. Eliminamos duplicados y columnas necesarias.\n",
    "1. Reemplazamos superficie cubierta mayor que superficie total con superficie total.\n",
    "1. Imputamos correctamente los valores de superficie total y cubierta mal imputados por la posición del \".\"\n",
    "1. Rellenamos null values con la mediana del valor faltante teniendo en cuenta tipo de propiedad, barrio y habitaciones.\n",
    "1. Quitamos outliars mediante rango intercuartílico.\n",
    "1. Aplicamos Word cloud para obtener caracteristicas relevantes de las publicaciones.\n",
    "1. Aplicamos variables dummies.\n",
    "1. Aplicamos reduccion de dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad de propiedades por zona\n",
    "sns.countplot(x = \"zone\", data = propiedades, dodge=False,palette= \"flare\",\n",
    "              order = propiedades['zone'].value_counts().index)\n",
    "#Formato de la gráfica\n",
    "plt.title('Propiedades por zona')\n",
    "plt.xlabel('Zona')\n",
    "plt.ylabel('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad de propiedades por zona\n",
    "sns.countplot(x = \"property_type\", data = propiedades, dodge=False,palette= \"flare\",\n",
    "              order = propiedades['property_type'].value_counts().index)\n",
    "#Formato de la gráfica\n",
    "plt.title('Tipos de propiedad')\n",
    "plt.xlabel('Tipos de propiedad')\n",
    "plt.ylabel('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''FILTRAMOS POR ZONA Y TIPOS DE PROPIEDAD CON MAYOR CANTIDAD DE PROPIEDADES'''\n",
    "ciudad_donde_hay_mas_propiedades = propiedades.zone.value_counts().idxmax()\n",
    "property_type_max = list(propiedades.property_type.value_counts().nlargest(3).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal = propiedades[propiedades.zone.isin([ciudad_donde_hay_mas_propiedades]) & propiedades.property_type.isin(property_type_max)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''IDENTIFICAMOS DUPLICADOS Y ELIMINAMOS DUPLICADOS'''\n",
    "duplicate_rows_df = capital_federal[capital_federal.duplicated()]\n",
    "print('Number of duplicate rows: ', duplicate_rows_df.shape)\n",
    "capital_federal = capital_federal.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ELIMINAMOS COLUMNAS INNECESARIAS'''\n",
    "capital_federal = capital_federal.drop(['start_date', 'end_date','created_on','operation_type','currency','country'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''HAY PROPIEDADES CON MAYOR SUPERFICIE CUBIERTA QUE TOTAL. REEMPLAZAMOS ESTOS DATOS POR LA SUP TOTAL'''\n",
    "capital_federal['surface_covered'] = np.where(capital_federal['surface_covered'] >= capital_federal.surface_total, capital_federal['surface_total'], capital_federal['surface_covered'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identificamos null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal.isna().sum()/capital_federal.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = capital_federal.isnull()\n",
    "heat=sns.heatmap(dat.T, cmap='YlGnBu',xticklabels=False)\n",
    "plt.title('Datos faltantes')\n",
    "plt.xlabel('Instancias dataset')\n",
    "plt.ylabel('Columnas dataset')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''REALIZAMOS BOXPLOT DEL PRECIO Y ZONA PARA IDENTIFICAR SI TENEMOS OUTLIERS. '''\n",
    "sns.boxplot(x = 'price', y = 'property_type', hue= 'property_type', data = capital_federal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitamos dato erroneo antes del pre procesamiento. \n",
    "capital_federal = capital_federal[capital_federal.price < 10000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''REALIZAMOS BOXPLOT DE LA SUPERFICIE TOTAL Y ZONA PARA IDENTIFICAR SI TENEMOS OUTLIERS. '''\n",
    "sns.boxplot(x = 'surface_total', y = 'property_type', hue= 'property_type', data = capital_federal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal.surface_total = [x/100 if x>2500 else x for x in capital_federal.surface_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''REALIZAMOS BOXPLOT DE LA SUPERFICIE CUBIERTA Y ZONA PARA IDENTIFICAR SI TENEMOS OUTLIERS. '''\n",
    "sns.boxplot(x = 'surface_covered', y = 'property_type', hue= 'property_type', data = capital_federal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal.surface_covered = [x/100 if x>2500 else x for x in capital_federal.surface_covered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Llenamos null values con la mediana teniendo en cuenta el tipo de propiedad, barrio y cantidad de habitaciones.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal['surface_covered'].fillna(capital_federal.groupby(['property_type','quarter','rooms','bedrooms'])['surface_covered'].transform(pd.Series.median), inplace = True)\n",
    "capital_federal['surface_total'].fillna(capital_federal.groupby(['property_type','quarter','rooms','bedrooms'])['surface_total'].transform(pd.Series.median), inplace = True)\n",
    "capital_federal['bathrooms'].fillna(capital_federal.groupby(['property_type','quarter','rooms','bedrooms'])['bathrooms'].transform(pd.Series.median).round(0), inplace = True)\n",
    "capital_federal.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IQR por tipo de propiedad.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUITAMOS VALORES ATIPICOS. ELEGIMOS RANGO INTERCUATILICO POR LA DISTRIBUCION DE LOS DATOS\n",
    "\n",
    "departamento = capital_federal[capital_federal['property_type'] == 'Departamento']\n",
    "\n",
    "casa = capital_federal[capital_federal['property_type'] == 'Casa']\n",
    "\n",
    "PH = capital_federal[capital_federal['property_type'] == 'PH']\n",
    "\n",
    "\n",
    "Q1_departamento = departamento.quantile(0.25).round(2)\n",
    "Q3_departamento = departamento.quantile(0.75).round(2)\n",
    "IQR_departamento = Q3_departamento - Q1_departamento\n",
    "print('IQR de los departamentos es de:',IQR_departamento)\n",
    "capital_federal_departamentos = departamento[~((departamento < (Q1_departamento - 1.5 * IQR_departamento)) |(departamento > (Q3_departamento + 1.5 * IQR_departamento))).any(axis=1)]\n",
    "\n",
    "Q1_casa = casa.quantile(0.25).round(2)\n",
    "Q3_casa = casa.quantile(0.75).round(2)\n",
    "IQR_casa = Q3_casa - Q1_casa\n",
    "print('IQR de las casas es de:',IQR_casa)\n",
    "capital_federal_casas = casa[~((casa < (Q1_casa - 1.5 * IQR_casa)) |(casa > (Q3_casa+ 1.5 * IQR_casa))).any(axis=1)]\n",
    "\n",
    "Q1_PH = PH.quantile(0.25).round(2)\n",
    "Q3_PH = PH.quantile(0.75).round(2)\n",
    "IQR_PH = Q3_PH - Q1_PH\n",
    "print('IQR de los PH es de:',IQR_PH)\n",
    "capital_federal_PHS = PH[~((PH < (Q1_PH - 1.5 * IQR_PH)) |(PH > (Q3_PH+ 1.5 * IQR_PH))).any(axis=1)]\n",
    "\n",
    "\n",
    "capital_federal = pd.concat([capital_federal_departamentos, capital_federal_casas,capital_federal_PHS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agregamos columna precio x mt2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal['mt2'] = capital_federal['price']/capital_federal['surface_total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pivot by quarter and property type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_quarter_price = capital_federal.pivot_table(columns = ['property_type'], values = ['price'], index = ['quarter'], aggfunc = 'mean').round(2)\n",
    "cf_quarter_price = cf_quarter_price.reset_index()\n",
    "cf_quarter_price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precio medio quarters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarters_caros = capital_federal.groupby('quarter').mean().sort_values(('price'),ascending=False).round(2)\n",
    "quarters_caros.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = capital_federal, hue='property_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISTRIBUCION DEL PRECIO DE LAS PROPIEDADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = capital_federal, x = 'price', hue='property_type', color = 'skyblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad de pasos por tipo de vehiculo en los días de la semana.\n",
    "plt.figure(figsize = (6,6))\n",
    "sns.barplot(data=capital_federal, x='property_type', y ='price', palette= \"flare\",order = capital_federal['property_type'].value_counts().index)\n",
    "\n",
    "#Formato de la gráfica\n",
    "plt.title('Property type by price')\n",
    "plt.xlabel('Property type')\n",
    "plt.ylabel('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (19,7))\n",
    "sns.barplot(x = \"quarter\",y='price', data = capital_federal, palette= \"flare\",order = capital_federal['quarter'].value_counts().index)\n",
    "plt.title(\"Precio medio por barrio\")\n",
    "plt.ylabel(\"Precio\")\n",
    "plt.xlabel(\"Barrio\")\n",
    "plt.xticks(rotation=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precio medio por tipo de propiedad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal_mean_price = capital_federal.pivot_table(values = 'price', index = ['property_type'], aggfunc = 'mean').round(2)\n",
    "capital_federal_mean_price = capital_federal_mean_price.reset_index()\n",
    "print(capital_federal_mean_price.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Superficie media por tipo de propiedad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal_mean_supercifie = capital_federal.pivot_table(values = 'surface_total', index = ['property_type'], aggfunc = 'mean').round(2)\n",
    "capital_federal_mean_supercifie = capital_federal_mean_supercifie.reset_index()\n",
    "print(capital_federal_mean_supercifie.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(capital_federal.corr(),cmap='YlGnBu',annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasar todos a minuscula y agregar stopwords\n",
    "capital_federal['title']       = capital_federal['title'].str.lower()\n",
    "capital_federal['description']       = capital_federal['description'].str.lower()\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "#nltk librería de análisis de lenguaje\n",
    "import nltk\n",
    "\n",
    "#Este proceso puede hacerse antes de forma manual, descargar las stopwords de la librería nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words_sp = set(stopwords.words('spanish'))\n",
    "stop_words_sp = ['Venta','Departamento','ph','u','s','todas','unidad','intermediación','acceso','encuentra','encuentran','supercifies','flores','aproximadas','parte', 'superficie', 'caracteristicas', 'balvanera', 'dpto','caracteristica', 'toda', 'conclusión', 'sujetos', 'publicadas', 'consignadas', 'medidas', 'expensas', 'disponibilidad','contractual','dormitorios','publicada','urquiza','accedé','servicio','fotos','unidades','publicadas' 'accedé', 'foto', 'salida', 'sujetas', 'carácter', 'lendar','barrio','norte','baño', 'previo', 'aviso', 'cuenta', 'oportunidad', 'verificación','querés','comprá','simulá','podés','préstamo','sujeta','tipo','deja','ser','placard','cuadras','modificado','constancia','bano','inmueble','caracter', 'excelente', 'verificacion', 'n', 'queres', 'podes', 'accede', 'ajuste', 'mls', 'id','puede','dormitorio', 'ambientes','cuota','prestamo', 'p','pisos','dormitorio','precio','apto','profesional','ambiente','living','comedor','cuadra','corredor','completo','piso','simula','propiedad','responsable','dos','amb','belgrano','edificio','valor','villa','crespo','br', 'Almagro', 'Palermo', 'Villa crespo', 'casa', 'Depto', 'Caballito','Capital federal','capital', 'federal', 'Recoleta','capital federal'] + list(stop_words_sp)\n",
    "\n",
    "text = \" \".join(x for x in capital_federal.description)\n",
    "print (\"Hay {} palabras en el total de descripciones de los anuncios de la base\".format(len(text)))\n",
    "\n",
    "#stop_words_sp.update([\"br\"])\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stop_words_sp, background_color=\"white\").generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "text = \" \".join(x for x in capital_federal.title)\n",
    "print (\"Hay {} palabras en el total de descripciones de los anuncios de la base\".format(len(text)))\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stop_words_sp, background_color=\"white\").generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal['title']       = capital_federal['title'].str.lower()\n",
    "capital_federal['title']       = capital_federal['title'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "capital_federal['description'] = capital_federal['description'].str.lower()\n",
    "capital_federal['description'] = capital_federal['description'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "\n",
    "capital_federal['cochera']  = ((capital_federal['description'].str.contains('cochera|garage', na=False)) | (capital_federal['title'].str.contains('cochera|garage', na=False))).astype(int)\n",
    "capital_federal['balcon']   = ((capital_federal['description'].str.contains('balcon|balcón', na=False))         | (capital_federal['title'].str.contains('balcon|balcón', na=False))).astype(int)\n",
    "capital_federal['frente']   = ((capital_federal['description'].str.contains('frente', na=False))         | (capital_federal['title'].str.contains('frente', na=False))).astype(int)\n",
    "capital_federal['terraza']  = ((capital_federal['description'].str.contains('terraza', na=False))    | (capital_federal['title'].str.contains('terraza', na=False))).astype(int)\n",
    "\n",
    "print('Publicaciones con cocheras:', capital_federal['cochera' ].sum())\n",
    "print('Publicaciones con balcon:  ', capital_federal['balcon'  ].sum())\n",
    "print('Publicaciones frente:      ', capital_federal['frente'  ].sum())\n",
    "print('Publicaciones con terraza:', capital_federal['terraza' ].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CANTIDAD DE PROPIEDADES POR ZONA'''\n",
    "'''CANTIDAD DE PROPIEDADES POR BARRIO '''\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(y = \"property_type\", hue = \"property_type\", data = capital_federal, dodge=False,\n",
    "              order = capital_federal['property_type'].value_counts().index)\n",
    "plt.title(\"Cantidad de anuncios por zona\")\n",
    "plt.xlabel(\"Cantidad de anuncios\")\n",
    "plt.ylabel(\"\")\n",
    "plt.legend(\"\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(y = \"quarter\", hue = \"property_type\", data = capital_federal, dodge=False,\n",
    "              order = capital_federal['quarter'].value_counts().index)\n",
    "plt.title(\"Cantidad de anuncios por barrio\")\n",
    "plt.xlabel(\"Cantidad de anuncios\")\n",
    "plt.ylabel(\"\")\n",
    "plt.legend(loc='lower right', frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicamos un mapa en el que se puede observar el precio de las propiedades**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages, see https://python-visualization.github.io/folium/\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# center to the mean of all points\n",
    "mapa_capital_federal = folium.Map(location=capital_federal[[\"lat\", \"lon\"]].mean().to_list(),zoom_start=15)\n",
    "\n",
    "# if the points are too close to each other, cluster them, create a cluster overlay with MarkerCluster\n",
    "marker_cluster = MarkerCluster().add_to(mapa_capital_federal)\n",
    "\n",
    "# draw the markers and assign popup and hover texts\n",
    "# add the markers the the cluster layers so that they are automatically clustered\n",
    "for i,r in capital_federal.iterrows():\n",
    "    location = (r[\"lat\"], r[\"lon\"])\n",
    "    folium.Marker(location=location,\n",
    "                      popup = r['price'],\n",
    "                      tooltip=r['price'])\\\n",
    "    .add_to(marker_cluster)\n",
    "\n",
    "# display the map\n",
    "mapa_capital_federal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicamos dummies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal = capital_federal.drop(['title', 'description','zone'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal = pd.get_dummies(capital_federal, columns= ['property_type','quarter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduccion de dimensionalidad con PCA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SELECCIONAMOS NUESTRAS X, Y'''\n",
    "X, y = capital_federal.drop(['price'],axis=1), capital_federal['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estandarizamos nuestros datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scl = StandardScaler()\n",
    "x = scl.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "principalComponents  = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal = pd.concat([principalDf, capital_federal['price']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos ML a aplicar:\n",
    "1. Como benchmark una regresión lineal.\n",
    "1. Regularización con Lasso.\n",
    "1. XGBoost\n",
    "1. Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benchmark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DIVIDIMOS EN TRAIN, TEST, SPLIT, ESTANDARIZAMOS Y APLICAMOS MODELO XGB'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Proporcion de etiquetas positiva en los datos de Train: ', y_train.sum()/y_train.size)\n",
    "print('Proporcion de etiquetas positiva en los datos de Test: ', y_test.sum()/y_test.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento, predicción y errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_linear = linear_model.predict(X_train)\n",
    "y_test_pred_linear = linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train_linear = np.sqrt(mean_squared_error(y_train, y_train_pred_linear))\n",
    "rmse_test_linear = np.sqrt(mean_squared_error(y_test, y_test_pred_linear))\n",
    "print(f'Raíz del error cuadrático medio de linear model en Train: {rmse_train_linear.round(2)}')\n",
    "print(f'Raíz del error cuadrático medio de linear model en Test: {rmse_test_linear.round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE IMPORTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The intercept is ' + str(linear_model.intercept_.round(2)))\n",
    "print('The score is ' + str(linear_model.score(X_test, y_test).round(3)))\n",
    "importance_lineal = linear_model.coef_.round(2)\n",
    "for i,v in enumerate(importance_lineal):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GRAFICO FEATURE IMPORTANCES'''\n",
    "plt.bar([x for x in range(len(importance_lineal))], importance_lineal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento, predicción y errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_lasso = {'alpha': [0.1, 0.5, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lasso = RandomizedSearchCV(lasso, param_dist_lasso, cv=3,random_state = 42).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_lasso = reg_lasso.predict(X_train)\n",
    "y_test_pred_lasso = reg_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_trainlasso = np.sqrt(mean_squared_error(y_train, y_train_pred_lasso))\n",
    "rmse_testlasso = np.sqrt(mean_squared_error(y_test, y_test_pred_lasso))\n",
    "print(f'Raíz del error cuadrático medio en Train: {rmse_trainlasso.round(2)}')\n",
    "print(f'Raíz del error cuadrático medio en Test: {rmse_testlasso.round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE IMPORTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The intercept is ' + str(reg_lasso.best_estimator_.intercept_.round(2)))\n",
    "print('The score is ' + str(reg_lasso.score(X_test, y_test).round(3)))\n",
    "importance_lasso = reg_lasso.best_estimator_.coef_.round(2)\n",
    "for i,v in enumerate(importance_lasso):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GRAFICO FEATURE IMPORTANCES'''\n",
    "plt.bar([x for x in range(len(importance_lasso))], importance_lasso)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicamos XGBoost y Random Forest optimizando hiperparametros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBOOST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_estimators':[2,4,6,8,10],\n",
    "         'eta': [0.1,0.5,1],\n",
    "         'max_depth': [3,5,7,9,12]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = RandomizedSearchCV(xgb, param,n_iter=10, random_state=42, cv=4).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''OBSERVAMOS LOS MEJORES PARAMETROS Y EL MEJOR SCORE'''\n",
    "print(\"Mejores parametros del modelo xgb: \"+str(model_xgb.best_params_))\n",
    "print(\"Mejor Score: \"+str(model_xgb.best_score_.round(3))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''REALIZAMOS LAS PREDICCIONES'''\n",
    "y_train_pred_xgb = model_xgb.predict(X_train)\n",
    "y_test_pred_xgb = model_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''EVALUAMOS MEDIANTE EL ERROR CUADRATICO MEDIO, METRICA UTILIZADA A LO LARGO DEL PROYECTO PARA COMPARAR RESULTADOS.'''\n",
    "rmse_train_xgb = np.sqrt(mean_squared_error(y_train, y_train_pred_xgb))\n",
    "rmse_test_xgb = np.sqrt(mean_squared_error(y_test, y_test_pred_xgb))\n",
    "print(f'Raíz del error cuadrático medio en Train xgb: {rmse_train_xgb.round(2)}')\n",
    "print(f'Raíz del error cuadrático medio en Test xgb: {rmse_test_xgb.round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE IMPORTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_xgb = model_xgb.best_estimator_.feature_importances_.round(3)\n",
    "for i,v in enumerate(importances_xgb):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GRAFICO FEATURE IMPORTANCES'''\n",
    "plt.bar([x for x in range(len(importances_xgb))], importances_xgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RANDOM FOREST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''HIPERPARAMETROS DE NUESTRO RANDOM FOREST'''\n",
    "param = {'max_depth': [13,15,20,25],\n",
    "         'n_estimators' : [80],\n",
    "        'max_features': ['auto', 'sqrt', 'log2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = RandomizedSearchCV(forest, param,n_iter=10, random_state=42, cv=4, n_jobs = -1).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mejores parametros del modelo random forest: \"+str(model_forest.best_params_))\n",
    "print(\"Mejor Score: \"+str(model_forest.best_score_.round(3))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''REALIZAMOS PREDICCIONES'''\n",
    "y_train_pred_forest = model_forest.predict(X_train) \n",
    "y_test_pred_forest = model_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''EVALUAMOS MEDIANTE EL ERROR CUADRATICO MEDIO, METRICA UTILIZADA A LO LARGO DEL PROYECTO PARA COMPARAR RESULTADOS.'''\n",
    "rmse_train_forest = np.sqrt(mean_squared_error(y_train, y_train_pred_forest))\n",
    "rmse_test_forest = np.sqrt(mean_squared_error(y_test, y_test_pred_forest))\n",
    "print(f'Raíz del error cuadrático medio en Train random forest: {rmse_train_forest.round(2)}')\n",
    "print(f'Raíz del error cuadrático medio en Test random forest: {rmse_test_forest.round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE IMPORTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_importances = model_forest.best_estimator_.feature_importances_.round(3)\n",
    "for i,v in enumerate(forest_importances):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GRAFICO FEATURE IMPORTANCES'''\n",
    "plt.bar([x for x in range(len(forest_importances))], forest_importances)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Best estimator of the forest 48'''\n",
    "tree_48 = model_forest.best_estimator_.estimators_[47]\n",
    "print(tree_48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graficamos los errores de cada uno de los modelos aplicados.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GRAFICAMOS LOS ERRORES, LA DISPERSIÓN DE CADA UNO DE LOS MODELOS ANALIZADOS.'''\n",
    "modelos = ['Linear Model', 'Regularization lasso', 'XGBoost', 'Random Forest']\n",
    "\n",
    "for i, model in enumerate([linear_model,reg_lasso, model_xgb, model_forest]):\n",
    "    for pred_train, y_train_pred in enumerate([y_train_pred_linear,y_train_pred_lasso,y_train_pred_xgb,y_train_pred_forest]):\n",
    "        pred_train = model.predict(X_train)\n",
    "        for pred_test, y_test_pred in enumerate([y_test_pred_linear,y_test_pred_lasso,y_test_pred_xgb,y_test_pred_forest]): \n",
    "            pred_test = model.predict(X_test)\n",
    "            for rmse_train in enumerate([rmse_train_linear, rmse_trainlasso, rmse_train_xgb, rmse_train_forest]):\n",
    "                rmse_train = np.sqrt(mean_squared_error(y_train, pred_train))\n",
    "                for rmse_test in enumerate([rmse_test_linear, rmse_testlasso, rmse_test_xgb, rmse_test_forest]):\n",
    "                    rmse_test = np.sqrt(mean_squared_error(y_test, pred_test))    \n",
    "    \n",
    "    print(f'Modelo: {modelos[i]}')\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, pred_test))\n",
    "    print(f'Raíz del error cuadrático medio en Train: {rmse_train}')\n",
    "    print(f'Raíz del error cuadrático medio en Test: {rmse_test}')\n",
    "    \n",
    "    plt.figure(figsize = (8,4))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.distplot(y_train - pred_train, bins = 20, label = 'train')\n",
    "    sns.distplot(y_test - pred_test, bins = 20, label = 'test')\n",
    "    plt.xlabel('errores')\n",
    "    plt.legend()\n",
    "\n",
    "    ax = plt.subplot(1,2,2)\n",
    "    ax.scatter(y_test,pred_test, s =2)    \n",
    "    lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes]\n",
    "    ]\n",
    "    \n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('y (test)')\n",
    "    plt.ylabel('y_pred (test)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Luego de haber realizado el entrenamiento de todos los modelos y observar resultados concluimos que:**\n",
    "\n",
    "El modelo ha mejorado considerablemente su predicción respecto del proyecto anterior.\n",
    "   1. Consideramos que esto se da por:\n",
    "    1. Limpieza mas detallada en el dataset.\n",
    "        1. En lo que respecta a limpieza, hemos encontrado que en muchas propiedades, en las columnas surface covered y surface total, la imputación de los m2 estaban erronea el **\".\"**. Para subsanar este error he dividido por 100 a estas superficies para que queden correctamente imputadas y no me generen un desvío en los datos. Al realizar esto, el llenado de null values con la mediana es mas precisa, el IQR aplicado de igual manera.\n",
    "    1. Cambio  en llenado de null values.\n",
    "    1. Dummies aplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluación de modelos**\n",
    "1. Se puede observar que el último modelo aplicado \"Random Forest\" está overfited, por lo que lo descartamos.\n",
    "1. El XGBoost que obtenemos un resultado mas realista y no overfiteado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporamos información de una fuente externa.\n",
    "Es el precio medio de los distintos barrios de CABA según la BBDD de la Universidad de San Andres.\n",
    "Es información simplemente la vamos a utilizar para comparar la media de precios de ambas BBDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Descarga de los datos aquí.](https://udesa.edu.ar/indices-meli/ventas). Barrios CABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descargamos el dataset y lo leemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caba = pd.read_excel(('ventascaba_202105.xlsx'),\n",
    "     engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = pd.read_csv('DS_Proyecto_01_Datos_Properati.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos a miniscula el nombre de los barrio para poder unirlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(caba['Barrio'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(propiedades['quarter'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caba[\"Barrio\"].map(lambda Barrio: Barrio.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upcase_first_letter(s):\n",
    "    return s[0].upper() + s[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabla pivot de la media\n",
    "barrios = caba.pivot_table(index = ['Barrio'],values = 'Mediana Flujo', aggfunc = 'mean')\n",
    "barrios = barrios.reset_index()\n",
    "barrios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad de propiedades por barrio\n",
    "sns.countplot(x = \"Barrio\", data = caba, dodge=False,palette= \"flare\",\n",
    "              order = caba['Barrio'].value_counts().index)\n",
    "#Formato de la gráfica\n",
    "plt.title('Propiedades por barrio')\n",
    "plt.xlabel('Barrio')\n",
    "plt.ylabel('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importa de nuevo la BBDD de properati y realizamos la misma limpieza que para el modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CAMBIAMOS NOMBRE A LAS COLUMNAS'''\n",
    "propiedades = properties.rename(columns={'l1': 'country','l2':'zone','l3':'quarter'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''FILTRAMOS POR ZONA Y TIPOS DE PROPIEDAD CON MAYOR CANTIDAD DE PROPIEDADES'''\n",
    "ciudad_donde_hay_mas_propiedades = propiedades.zone.value_counts().idxmax()\n",
    "property_type_max = list(propiedades.property_type.value_counts().nlargest(3).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal = propiedades[propiedades.zone.isin([ciudad_donde_hay_mas_propiedades]) & propiedades.property_type.isin(property_type_max)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''IDENTIFICAMOS DUPLICADOS Y ELIMINAMOS DUPLICADOS'''\n",
    "duplicate_rows_df = capital_federal[capital_federal.duplicated()]\n",
    "print('Number of duplicate rows: ', duplicate_rows_df.shape)\n",
    "capital_federal = capital_federal.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ELIMINAMOS COLUMNAS INNECESARIAS'''\n",
    "capital_federal = capital_federal.drop(['start_date', 'end_date','created_on','operation_type','currency','country'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''HAY PROPIEDADES CON MAYOR SUPERFICIE CUBIERTA QUE TOTAL. REEMPLAZAMOS ESTOS DATOS POR LA SUP TOTAL'''\n",
    "capital_federal['surface_covered'] = np.where(capital_federal['surface_covered'] >= capital_federal.surface_total, capital_federal['surface_total'], capital_federal['surface_covered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitamos dato erroneo antes del pre procesamiento. \n",
    "capital_federal = capital_federal[capital_federal.price < 10000000]\n",
    "capital_federal.surface_total = [x/100 if x>2500 else x for x in capital_federal.surface_total]\n",
    "capital_federal.surface_covered = [x/100 if x>2500 else x for x in capital_federal.surface_covered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal['surface_covered'].fillna(capital_federal.groupby(['property_type','quarter','rooms','bedrooms'])['surface_covered'].transform(pd.Series.median), inplace = True)\n",
    "capital_federal['surface_total'].fillna(capital_federal.groupby(['property_type','quarter','rooms','bedrooms'])['surface_total'].transform(pd.Series.median), inplace = True)\n",
    "capital_federal['bathrooms'].fillna(capital_federal.groupby(['property_type','quarter','rooms','bedrooms'])['bathrooms'].transform(pd.Series.median).round(0), inplace = True)\n",
    "capital_federal.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUITAMOS VALORES ATIPICOS. ELEGIMOS RANGO INTERCUATILICO POR LA DISTRIBUCION DE LOS DATOS\n",
    "\n",
    "departamento = capital_federal[capital_federal['property_type'] == 'Departamento']\n",
    "\n",
    "casa = capital_federal[capital_federal['property_type'] == 'Casa']\n",
    "\n",
    "PH = capital_federal[capital_federal['property_type'] == 'PH']\n",
    "\n",
    "\n",
    "Q1_departamento = departamento.quantile(0.25).round(2)\n",
    "Q3_departamento = departamento.quantile(0.75).round(2)\n",
    "IQR_departamento = Q3_departamento - Q1_departamento\n",
    "#print('IQR de los departamentos es de:',IQR_departamento)\n",
    "capital_federal_departamentos = departamento[~((departamento < (Q1_departamento - 1.5 * IQR_departamento)) |(departamento > (Q3_departamento + 1.5 * IQR_departamento))).any(axis=1)]\n",
    "\n",
    "Q1_casa = casa.quantile(0.25).round(2)\n",
    "Q3_casa = casa.quantile(0.75).round(2)\n",
    "IQR_casa = Q3_casa - Q1_casa\n",
    "#print('IQR de las casas es de:',IQR_casa)\n",
    "capital_federal_casas = casa[~((casa < (Q1_casa - 1.5 * IQR_casa)) |(casa > (Q3_casa+ 1.5 * IQR_casa))).any(axis=1)]\n",
    "\n",
    "Q1_PH = PH.quantile(0.25).round(2)\n",
    "Q3_PH = PH.quantile(0.75).round(2)\n",
    "IQR_PH = Q3_PH - Q1_PH\n",
    "#print('IQR de los PH es de:',IQR_PH)\n",
    "capital_federal_PHS = PH[~((PH < (Q1_PH - 1.5 * IQR_PH)) |(PH > (Q3_PH+ 1.5 * IQR_PH))).any(axis=1)]\n",
    "\n",
    "\n",
    "capital_federal = pd.concat([capital_federal_departamentos, capital_federal_casas,capital_federal_PHS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_federal['mt2'] = capital_federal['price']/capital_federal['surface_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unimos las dos BBDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(capital_federal, barrios ,left_on=\"quarter\", right_on=\"Barrio\")\n",
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_merge.drop(['Barrio'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos la media del precio de mt2 según la BBDD de properati y la de San Andres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabla pivot de la media\n",
    "comparativa = df_merge.pivot_table(index = ['quarter'],values = ['mt2','Mediana Flujo']).round(2)\n",
    "comparativa = comparativa.reset_index()\n",
    "comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Argegamos columna para distinguir cual es mayor\n",
    "df_merge['comparativa'] = np.where(df_merge[\"mt2\"] >= df_merge[\"Mediana Flujo\"], 1, 0)\n",
    "df_merge.comparativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafico que compara la media de precio en cada barrio según cada BBDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (19,7))\n",
    "sns.countplot(x = \"quarter\",hue='comparativa', data = df_merge, palette= \"flare\",order = df_merge['quarter'].value_counts().index)\n",
    "plt.title(\"Precio medio por barrio\")\n",
    "plt.ylabel(\"Precio mt2\")\n",
    "plt.xlabel(\"Barrio\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='lower right', frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Proyecto_01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
